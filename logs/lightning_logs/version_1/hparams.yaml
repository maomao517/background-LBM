config_yaml:
  batch_size: 4
  bridge_noise_sigma: 0.005
  conditioning_images_keys: []
  conditioning_masks_keys: []
  latent_loss_type: l2
  latent_loss_weight: 1.0
  learning_rate: 4e-5
  log_interval: 500
  max_epochs: 50
  num_steps: &id008
  - 1
  - 4
  optimizer: AdamW
  pixel_loss_type: lpips
  pixel_loss_weight: 10.0
  prob:
  - 0.25
  - 0.25
  - 0.25
  - 0.25
  resume_from_checkpoint: true
  save_ckpt_path: ./checkpoints
  save_interval: 5000
  selected_timesteps:
  - 250
  - 500
  - 750
  - 1000
  timestep_sampling: custom_timesteps
  train_shards:
  - pipe:cat "/home/notebook/code/personal/S9059881/LBM/dataset/train.tar"
  unet_input_channels: 4
  vae_num_channels: 4
  validation_shards:
  - pipe:cat "/home/notebook/code/personal/S9059881/LBM/dataset/valid.tar"
  wandb_project: lbm-surface-flows
denoiser: !!python/object/apply:diffusers.configuration_utils.FrozenDict
  dictitems:
    _use_default_values: &id001
    - sample_size
    act_fn: silu
    addition_embed_type: null
    addition_embed_type_num_heads: 64
    addition_time_embed_dim: null
    attention_head_dim: &id002
    - 5
    - 10
    - 20
    attention_type: default
    block_out_channels: &id003
    - 320
    - 640
    - 1280
    center_input_sample: false
    class_embed_type: null
    class_embeddings_concat: false
    conv_in_kernel: 3
    conv_out_kernel: 3
    cross_attention_dim: &id004
    - 320
    - 640
    - 1280
    cross_attention_norm: null
    down_block_types: &id005
    - DownBlock2D
    - CrossAttnDownBlock2D
    - CrossAttnDownBlock2D
    downsample_padding: 1
    dropout: 0.0
    dual_cross_attention: false
    encoder_hid_dim: null
    encoder_hid_dim_type: null
    flip_sin_to_cos: true
    freq_shift: 0
    in_channels: 4
    layers_per_block: 2
    mid_block_only_cross_attention: null
    mid_block_scale_factor: 1
    mid_block_type: UNetMidBlock2DCrossAttn
    norm_eps: 1.0e-05
    norm_num_groups: 32
    num_attention_heads: null
    num_class_embeds: null
    only_cross_attention: false
    out_channels: 4
    projection_class_embeddings_input_dim: null
    resnet_out_scale_factor: 1.0
    resnet_skip_time_act: false
    resnet_time_scale_shift: default
    reverse_transformer_layers_per_block: null
    sample_size: null
    time_cond_proj_dim: null
    time_embedding_act_fn: null
    time_embedding_dim: null
    time_embedding_type: positional
    timestep_post_act: null
    transformer_layers_per_block: &id006
    - 1
    - 2
    - 10
    up_block_types: &id007
    - CrossAttnUpBlock2D
    - CrossAttnUpBlock2D
    - UpBlock2D
    upcast_attention: null
    use_linear_projection: true
  state:
    _FrozenDict__frozen: true
    _use_default_values: *id001
    act_fn: silu
    addition_embed_type: null
    addition_embed_type_num_heads: 64
    addition_time_embed_dim: null
    attention_head_dim: *id002
    attention_type: default
    block_out_channels: *id003
    center_input_sample: false
    class_embed_type: null
    class_embeddings_concat: false
    conv_in_kernel: 3
    conv_out_kernel: 3
    cross_attention_dim: *id004
    cross_attention_norm: null
    down_block_types: *id005
    downsample_padding: 1
    dropout: 0.0
    dual_cross_attention: false
    encoder_hid_dim: null
    encoder_hid_dim_type: null
    flip_sin_to_cos: true
    freq_shift: 0
    in_channels: 4
    layers_per_block: 2
    mid_block_only_cross_attention: null
    mid_block_scale_factor: 1
    mid_block_type: UNetMidBlock2DCrossAttn
    norm_eps: 1.0e-05
    norm_num_groups: 32
    num_attention_heads: null
    num_class_embeds: null
    only_cross_attention: false
    out_channels: 4
    projection_class_embeddings_input_dim: null
    resnet_out_scale_factor: 1.0
    resnet_skip_time_act: false
    resnet_time_scale_shift: default
    reverse_transformer_layers_per_block: null
    sample_size: null
    time_cond_proj_dim: null
    time_embedding_act_fn: null
    time_embedding_dim: null
    time_embedding_type: positional
    timestep_post_act: null
    transformer_layers_per_block: *id006
    up_block_types: *id007
    upcast_attention: null
    use_linear_projection: true
model_config:
  bridge_noise_sigma: 0.005
  input_key: image
  latent_loss_type: l2
  latent_loss_weight: 1.0
  logit_mean: 0.0
  logit_std: 1.0
  mask_key: mask
  name: LBMConfig
  pixel_loss_max_size: 512
  pixel_loss_type: lpips
  pixel_loss_weight: 10.0
  prob:
  - 0.25
  - 0.25
  - 0.25
  - 0.25
  selected_timesteps:
  - 250.0
  - 500.0
  - 750.0
  - 1000.0
  source_key: image
  target_key: normal
  timestep_sampling: custom_timesteps
pipeline_config: !!python/object:lbm.trainer.training_config.TrainingConfig
  backup_every: 50
  experiment_id: null
  learning_rate: 4.0e-05
  log_keys:
  - image
  - normal
  - mask
  log_samples_model_kwargs:
    input_shape: null
    num_steps: *id008
  lr_scheduler_frequency: 1
  lr_scheduler_interval: step
  lr_scheduler_kwargs: {}
  lr_scheduler_name: null
  metrics: null
  name: TrainingConfig
  optimizer_kwargs: {}
  optimizer_name: AdamW
  tracking_metrics: null
  trainable_params:
  - denoiser.*
sampling_noise_scheduler: !!python/object/apply:diffusers.configuration_utils.FrozenDict
  dictitems:
    _class_name: FlowMatchEulerDiscreteScheduler
    _diffusers_version: 0.19.0.dev0
    _use_default_values: &id009
    - max_shift
    - base_shift
    - shift
    - base_image_seq_len
    - shift_terminal
    - max_image_seq_len
    - invert_sigmas
    - use_dynamic_shifting
    - use_beta_sigmas
    - use_exponential_sigmas
    base_image_seq_len: 256
    base_shift: 0.5
    beta_end: 0.012
    beta_schedule: scaled_linear
    beta_start: 0.00085
    clip_sample: false
    interpolation_type: linear
    invert_sigmas: false
    max_image_seq_len: 4096
    max_shift: 1.15
    num_train_timesteps: 1000
    prediction_type: epsilon
    sample_max_value: 1.0
    set_alpha_to_one: false
    shift: 1.0
    shift_terminal: null
    skip_prk_steps: true
    steps_offset: 1
    timestep_spacing: leading
    trained_betas: null
    use_beta_sigmas: false
    use_dynamic_shifting: false
    use_exponential_sigmas: false
    use_karras_sigmas: false
  state:
    _FrozenDict__frozen: true
    _class_name: FlowMatchEulerDiscreteScheduler
    _diffusers_version: 0.19.0.dev0
    _use_default_values: *id009
    base_image_seq_len: 256
    base_shift: 0.5
    beta_end: 0.012
    beta_schedule: scaled_linear
    beta_start: 0.00085
    clip_sample: false
    interpolation_type: linear
    invert_sigmas: false
    max_image_seq_len: 4096
    max_shift: 1.15
    num_train_timesteps: 1000
    prediction_type: epsilon
    sample_max_value: 1.0
    set_alpha_to_one: false
    shift: 1.0
    shift_terminal: null
    skip_prk_steps: true
    steps_offset: 1
    timestep_spacing: leading
    trained_betas: null
    use_beta_sigmas: false
    use_dynamic_shifting: false
    use_exponential_sigmas: false
    use_karras_sigmas: false
training:
  backup_every: 50
  experiment_id: null
  learning_rate: 4.0e-05
  log_keys:
  - image
  - normal
  - mask
  log_samples_model_kwargs:
    input_shape: null
    num_steps:
    - 1
    - 4
  lr_scheduler_frequency: 1
  lr_scheduler_interval: step
  lr_scheduler_kwargs: {}
  lr_scheduler_name: null
  metrics: null
  name: TrainingConfig
  optimizer_kwargs: {}
  optimizer_name: AdamW
  tracking_metrics: null
  trainable_params:
  - denoiser.*
training_noise_scheduler: !!python/object/apply:diffusers.configuration_utils.FrozenDict
  dictitems:
    _class_name: FlowMatchEulerDiscreteScheduler
    _diffusers_version: 0.19.0.dev0
    _use_default_values: &id010
    - max_shift
    - base_shift
    - shift
    - base_image_seq_len
    - shift_terminal
    - max_image_seq_len
    - invert_sigmas
    - use_dynamic_shifting
    - use_beta_sigmas
    - use_exponential_sigmas
    base_image_seq_len: 256
    base_shift: 0.5
    beta_end: 0.012
    beta_schedule: scaled_linear
    beta_start: 0.00085
    clip_sample: false
    interpolation_type: linear
    invert_sigmas: false
    max_image_seq_len: 4096
    max_shift: 1.15
    num_train_timesteps: 1000
    prediction_type: epsilon
    sample_max_value: 1.0
    set_alpha_to_one: false
    shift: 1.0
    shift_terminal: null
    skip_prk_steps: true
    steps_offset: 1
    timestep_spacing: leading
    trained_betas: null
    use_beta_sigmas: false
    use_dynamic_shifting: false
    use_exponential_sigmas: false
    use_karras_sigmas: false
  state:
    _FrozenDict__frozen: true
    _class_name: FlowMatchEulerDiscreteScheduler
    _diffusers_version: 0.19.0.dev0
    _use_default_values: *id010
    base_image_seq_len: 256
    base_shift: 0.5
    beta_end: 0.012
    beta_schedule: scaled_linear
    beta_start: 0.00085
    clip_sample: false
    interpolation_type: linear
    invert_sigmas: false
    max_image_seq_len: 4096
    max_shift: 1.15
    num_train_timesteps: 1000
    prediction_type: epsilon
    sample_max_value: 1.0
    set_alpha_to_one: false
    shift: 1.0
    shift_terminal: null
    skip_prk_steps: true
    steps_offset: 1
    timestep_spacing: leading
    trained_betas: null
    use_beta_sigmas: false
    use_dynamic_shifting: false
    use_exponential_sigmas: false
    use_karras_sigmas: false
vae:
  input_key: image
  name: AutoencoderKLDiffusersConfig
  revision: main
  subfolder: vae
  tiling_overlap: !!python/tuple
  - 16
  - 16
  tiling_size: !!python/tuple
  - 128
  - 128
  version: stabilityai/stable-diffusion-xl-base-1.0
verbose: false
